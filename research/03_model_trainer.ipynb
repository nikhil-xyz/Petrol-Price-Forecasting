{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nikhil\\\\OneDrive\\\\Desktop\\\\ML Projects\\\\Petrol-Price-Forecasting\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nikhil\\\\OneDrive\\\\Desktop\\\\ML Projects\\\\Petrol-Price-Forecasting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    p: int\n",
    "    d: int\n",
    "    q: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppf.constants import *\n",
    "from ppf.utils.common import create_directories, read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        model_trainer_config =  ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_path = config.model_path,\n",
    "            p = params.p,\n",
    "            d = params.d,\n",
    "            q = params.q\n",
    "        )\n",
    "        \n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ppf.logging import logger\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "    \n",
    "        dataset = pd.read_csv(self.config.data_path, index_col=False)  \n",
    "        dataset.set_index('Date', inplace=True)\n",
    "        dataset.index = pd.to_datetime(dataset.index)\n",
    "        # print(dataset.index)\n",
    "\n",
    "        model=ARIMA(dataset, order=(self.config.p, self.config.d, self.config.q))\n",
    "        model_fit=model.fit()\n",
    "        \n",
    "        # save model\n",
    "        pickle.dump(model, open(self.config.model_path, 'wb'))\n",
    "        logger.info(f'Model is stored as {self.config.model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 21:58:43,617: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-14 21:58:43,620: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-14 21:58:43,624: INFO: common: directory artifacts created]\n",
      "[2024-05-14 21:58:43,627: INFO: common: directory artifacts/model_trainer created]\n",
      "DatetimeIndex(['2003-06-01', '2003-07-01', '2003-08-01', '2003-09-01',\n",
      "               '2003-10-01', '2003-11-01', '2003-12-01', '2004-01-01',\n",
      "               '2004-02-01', '2004-03-01',\n",
      "               ...\n",
      "               '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01',\n",
      "               '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01',\n",
      "               '2018-11-01', '2018-12-01'],\n",
      "              dtype='datetime64[ns]', name='Date', length=187, freq=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhil\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nikhil\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\nikhil\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-14 21:58:44,629: INFO: 3592429050: Model is stored as artifacts/model_trainer/model.pkl]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhil\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config = model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
